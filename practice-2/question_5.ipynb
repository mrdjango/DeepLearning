{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                self._make_conv_block(in_channels + i * growth_rate, growth_rate)\n",
    "            )\n",
    "\n",
    "    def _make_conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            out = layer(torch.cat(features, 1))\n",
    "            features.append(out)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_classes, growth_rate=12, block_config=(6, 12, 24, 16)):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        in_channels = 64\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(in_channels, growth_rate, num_layers)\n",
    "            self.features.add_module(f\"denseblock{i + 1}\", block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = Transition(in_channels, in_channels // 2)\n",
    "                self.features.add_module(f\"transition{i + 1}\", trans)\n",
    "                in_channels = in_channels // 2\n",
    "        self.features.add_module(\"norm5\", nn.BatchNorm2d(in_channels))\n",
    "        self.features.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(64, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(76, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(88, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(100, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(112, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(124, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition1): Transition(\n",
      "      (conv): Conv2d(136, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(68, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(80, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(92, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(104, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(116, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(128, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(152, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): Sequential(\n",
      "          (0): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(164, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (9): Sequential(\n",
      "          (0): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(176, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (10): Sequential(\n",
      "          (0): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(188, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (11): Sequential(\n",
      "          (0): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(200, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition2): Transition(\n",
      "      (conv): Conv2d(212, 106, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(106, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(118, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(130, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm2d(142, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(142, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(154, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BatchNorm2d(166, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(166, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): BatchNorm2d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(178, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): BatchNorm2d(190, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(190, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): Sequential(\n",
      "          (0): BatchNorm2d(202, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(202, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (9): Sequential(\n",
      "          (0): BatchNorm2d(214, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(214, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (10): Sequential(\n",
      "          (0): BatchNorm2d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(226, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (11): Sequential(\n",
      "          (0): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(238, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (12): Sequential(\n",
      "          (0): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(250, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (13): Sequential(\n",
      "          (0): BatchNorm2d(262, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(262, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (14): Sequential(\n",
      "          (0): BatchNorm2d(274, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(274, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (15): Sequential(\n",
      "          (0): BatchNorm2d(286, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(286, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (16): Sequential(\n",
      "          (0): BatchNorm2d(298, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(298, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (17): Sequential(\n",
      "          (0): BatchNorm2d(310, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(310, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (18): Sequential(\n",
      "          (0): BatchNorm2d(322, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(322, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (19): Sequential(\n",
      "          (0): BatchNorm2d(334, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(334, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (20): Sequential(\n",
      "          (0): BatchNorm2d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(346, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (21): Sequential(\n",
      "          (0): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(358, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (22): Sequential(\n",
      "          (0): BatchNorm2d(370, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(370, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (23): Sequential(\n",
      "          (0): BatchNorm2d(382, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(382, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition3): Transition(\n",
      "      (conv): Conv2d(394, 197, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BatchNorm2d(197, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(197, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BatchNorm2d(209, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(209, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BatchNorm2d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(221, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm2d(233, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(233, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(245, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BatchNorm2d(257, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(257, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): BatchNorm2d(269, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(269, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): BatchNorm2d(281, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(281, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): Sequential(\n",
      "          (0): BatchNorm2d(293, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(293, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (9): Sequential(\n",
      "          (0): BatchNorm2d(305, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(305, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (10): Sequential(\n",
      "          (0): BatchNorm2d(317, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(317, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (11): Sequential(\n",
      "          (0): BatchNorm2d(329, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(329, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (12): Sequential(\n",
      "          (0): BatchNorm2d(341, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(341, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (13): Sequential(\n",
      "          (0): BatchNorm2d(353, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(353, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (14): Sequential(\n",
      "          (0): BatchNorm2d(365, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(365, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (15): Sequential(\n",
      "          (0): BatchNorm2d(377, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Conv2d(377, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(389, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Linear(in_features=389, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example instantiation\n",
    "model = DenseNet(num_classes=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **DenseBlock**:\n",
    "   - This is the fundamental building block of the DenseNet architecture.\n",
    "   - It consists of a series of densely connected convolutional layers.\n",
    "   - Each convolutional layer produces k feature maps, where k is the growth rate.\n",
    "   - The input to each convolutional layer is the concatenation of the feature maps from all preceding layers within the same block.\n",
    "\n",
    "2. **Transition Layer**:\n",
    "   - Transition layers are used to reduce the number of feature maps between dense blocks.\n",
    "   - They consist of a 1x1 convolutional layer followed by average pooling.\n",
    "   - The 1x1 convolutional layer reduces the number of feature maps, while average pooling reduces the spatial dimensions of the feature maps.\n",
    "\n",
    "3. **DenseNet**:\n",
    "   - The main architecture consists of multiple DenseBlocks interleaved with Transition layers.\n",
    "   - The first layer of the DenseNet is a standard convolutional layer with 7x7 kernel size and 64 output channels, followed by batch normalization and ReLU activation.\n",
    "   - After the initial convolutional layer, there is a max-pooling layer to downsample the spatial dimensions of the feature maps.\n",
    "   - Subsequent layers consist of a sequence of DenseBlocks and Transition layers.\n",
    "   - Each DenseBlock is followed by a Transition layer (except for the last DenseBlock).\n",
    "   - After all dense blocks, there's a final batch normalization layer and ReLU activation.\n",
    "   - The output of the final ReLU activation is passed through an adaptive average pooling layer to reduce the spatial dimensions to 1x1.\n",
    "   - Finally, the output is flattened and fed into a fully connected layer (linear layer) to produce the final output logits.\n",
    "\n",
    "4. **Batch Normalization**:\n",
    "   - Batch normalization is applied before each convolutional layer and linear layer.\n",
    "   - It normalizes the activations of the previous layer, helping to stabilize and accelerate the training process.\n",
    "\n",
    "5. **ReLU Activation**:\n",
    "   - Rectified Linear Unit (ReLU) activation function is applied after each batch normalization layer, introducing non-linearity to the network.\n",
    "\n",
    "6. **Max Pooling**:\n",
    "   - Max pooling is applied after the initial convolutional layer to downsample the spatial dimensions of the feature maps.\n",
    "\n",
    "7. **Adaptive Average Pooling**:\n",
    "   - Adaptive average pooling is used to reduce the spatial dimensions of the feature maps to a fixed size (1x1) regardless of the input size.\n",
    "   - This ensures that the network can accept inputs of varying sizes.\n",
    "\n",
    "8. **Linear Layer (Classifier)**:\n",
    "   - The output of the adaptive average pooling layer is flattened and fed into a linear layer.\n",
    "   - This linear layer acts as a classifier, mapping the feature representation to the final output logits, which represent the predicted class probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
