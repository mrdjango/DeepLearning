{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Deep Learning Practice (series 1)\n",
    "##### Mostafa Shahbazi Dill - id: 40252521602\n",
    "##### 2024-March-01\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import madgrad\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### 1. Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform to convert images to tensors\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Compute the number of input nodes\n",
    "input_nodes = 28 * 28  # MNIST images are 28x28 pixels\n",
    "\n",
    "# Compute the number of output nodes\n",
    "output_nodes = 10  # Since there are 10 classes (digits 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.1\n",
    "##### MLP model with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        output_size,\n",
    "        dropout_rate,\n",
    "        activation,\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input images\n",
    "\n",
    "        # x = torch.relu(self.fc1(x)) # default activation function\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.activation(self.fc2(x))\n",
    "        # x = torch.relu(self.fc2(x)) # default activation function\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2\n",
    "##### training loop and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    # print(f\"Accuracy on test set: {accuracy}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### 2.1\n",
    "##### optimization methods: SGD, Adam, RMSprop, MADGRAD (paper), mirrorMADGRAD (paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimization methods\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.5,\n",
    "    activation=torch.relu,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train with SGD optimizer\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01)\n",
    "train(model, criterion, optimizer_sgd, train_loader, epochs=5)\n",
    "accuracy_sgd = evaluate(model, test_loader)\n",
    "\n",
    "# Train with Adam optimizer\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.5,\n",
    "    activation=torch.relu,\n",
    ")\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, criterion, optimizer_adam, train_loader, epochs=5)\n",
    "accuracy_adam = evaluate(model, test_loader)\n",
    "\n",
    "# Train with RMSprop optimizer\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.5,\n",
    "    activation=torch.relu,\n",
    ")\n",
    "optimizer_rmsprop = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "train(model, criterion, optimizer_rmsprop, train_loader, epochs=5)\n",
    "accuracy_rmsprop = evaluate(model, test_loader)\n",
    "\n",
    "# Train with MADGRAD optimizer (our new optimizer according to the paper)\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.5,\n",
    "    activation=torch.relu,\n",
    ")\n",
    "optimizer_madgrad = madgrad.MADGRAD(\n",
    "    params=model.parameters(), decouple_decay=True, lr=0.001\n",
    ")\n",
    "train(model, criterion, optimizer_madgrad, train_loader, epochs=5)\n",
    "accuracy_madgrad = evaluate(model, test_loader)\n",
    "\n",
    "# Train with MirrorMADGRAD optimizer\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.5,\n",
    "    activation=torch.relu,\n",
    ")\n",
    "optimizer_mirrormadgrad = madgrad.MirrorMADGRAD(\n",
    "    params=model.parameters(), decouple_decay=True, lr=0.001\n",
    ")\n",
    "train(model, criterion, optimizer_mirrormadgrad, train_loader, epochs=5)\n",
    "accuracy_mirrormadgrad = evaluate(model, test_loader)\n",
    "\n",
    "\n",
    "print(f\">>(SGD)<<Accuracy: {accuracy_sgd}\")\n",
    "print(f\">>(Adam)<<Accuracy: {accuracy_adam}\")\n",
    "print(f\">>(RMSprop)<<Accuracy: {accuracy_rmsprop}\")\n",
    "print(f\">>(MADGRAD - paper op)<<Accuracy: {accuracy_madgrad}\")\n",
    "print(f\">>(MirrorMADGRAD - paper op)<<Accuracy: {accuracy_mirrormadgrad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### 3.1\n",
    "##### evaluate with different activation functions\n",
    "\n",
    "##### activation functions: ReLU, Sigmoid, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activation functions\n",
    "activations = [torch.relu, torch.sigmoid, torch.tanh]\n",
    "\n",
    "# Evaluate the model with different activation functions\n",
    "for activation in activations:\n",
    "    model = MLP(\n",
    "        input_nodes, 128, 64, output_nodes, dropout_rate=0.5, activation=activation\n",
    "    )\n",
    "\n",
    "    optimizer = madgrad.MADGRAD(params=model.parameters(), lr=0.001)\n",
    "    train(model, criterion, optimizer, train_loader, epochs=5)\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Accuracy with activation {activation.__name__}: {accuracy}\")\n",
    "\n",
    "print(f\"\\nOptimizer: {optimizer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 4.1\n",
    "#### Dropout rates: 0.1, 0.3, 0.5, 0.7, 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for dropout_rate in dropout_rates:\n",
    "    model = MLP(\n",
    "        input_size=input_nodes,\n",
    "        hidden_size1=128,\n",
    "        hidden_size2=64,\n",
    "        output_size=output_nodes,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=torch.sigmoid,\n",
    "    )\n",
    "\n",
    "    optimizer = madgrad.MADGRAD(params=model.parameters(), lr=0.001)\n",
    "    train(model, criterion, optimizer, train_loader, epochs=5)\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Accuracy with dropout rate {dropout_rate}: {accuracy}\")\n",
    "\n",
    "print(f\"\\nOptimizer: {optimizer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### 5.1\n",
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation transforms\n",
    "augmentation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Augmented dataset\n",
    "augmented_train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=augmentation_transform, download=True\n",
    ")\n",
    "augmented_train_loader = DataLoader(\n",
    "    augmented_train_dataset, batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "# Evaluate the model with augmented data\n",
    "model = MLP(\n",
    "    input_size=input_nodes,\n",
    "    hidden_size1=128,\n",
    "    hidden_size2=64,\n",
    "    output_size=output_nodes,\n",
    "    dropout_rate=0.1,\n",
    "    activation=torch.sigmoid,\n",
    ")\n",
    "optimizer = madgrad.MirrorMADGRAD(params=model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "train(model, criterion, optimizer, augmented_train_loader, epochs=5)\n",
    "accuracy_augmented = evaluate(model, test_loader)\n",
    "print(f\"Accuracy with data augmentation: {accuracy_augmented}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1\n",
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plt(model, criterion, optimizer, train_loader, epochs, batch_size):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        # for i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "        #     optimizer.zero_grad()\n",
    "        #     outputs = model(inputs)\n",
    "        #     loss = criterion(outputs, labels)\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "        #     running_loss += loss.item() * inputs.size(0)  # Multiply by batch size\n",
    "        #     if i % 100 == 0:\n",
    "        #         print(\n",
    "        #             f\"Epoch {epoch+1}, Batch {i}, Loss: {running_loss/(i*batch_size)}\"\n",
    "        #         )\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        epoch_loss = running_loss / len(\n",
    "            train_loader.dataset\n",
    "        )  # Divide by total number of samples\n",
    "        losses.append(epoch_loss)\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class MlpBatch(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        output_size,\n",
    "        dropout_rate,\n",
    "        activation,\n",
    "    ):\n",
    "        super(MlpBatch, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input images\n",
    "\n",
    "        # x = torch.relu(self.fc1(x)) # default activation function\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # x = torch.relu(self.fc2(x)) # default activation function\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size: 16\n",
      "Loss after mini-batch     1: 0.025\n",
      "Loss after mini-batch   101: 0.910\n",
      "Loss after mini-batch   201: 0.534\n",
      "Loss after mini-batch   301: 0.537\n",
      "Loss after mini-batch   401: 0.463\n",
      "Loss after mini-batch   501: 0.423\n",
      "Loss after mini-batch   601: 0.435\n",
      "Loss after mini-batch   701: 0.429\n",
      "Loss after mini-batch   801: 0.388\n",
      "Loss after mini-batch   901: 0.382\n",
      "Loss after mini-batch  1001: 0.333\n",
      "Loss after mini-batch  1101: 0.313\n",
      "Loss after mini-batch  1201: 0.350\n",
      "Loss after mini-batch  1301: 0.333\n",
      "Loss after mini-batch  1401: 0.347\n",
      "Loss after mini-batch  1501: 0.339\n",
      "Loss after mini-batch  1601: 0.346\n",
      "Loss after mini-batch  1701: 0.276\n",
      "Loss after mini-batch  1801: 0.338\n",
      "Loss after mini-batch  1901: 0.303\n",
      "Loss after mini-batch  2001: 0.342\n",
      "Loss after mini-batch  2101: 0.327\n",
      "Loss after mini-batch  2201: 0.327\n",
      "Loss after mini-batch  2301: 0.302\n",
      "Loss after mini-batch  2401: 0.288\n",
      "Loss after mini-batch  2501: 0.287\n",
      "Loss after mini-batch  2601: 0.288\n",
      "Loss after mini-batch  2701: 0.282\n",
      "Loss after mini-batch  2801: 0.290\n",
      "Loss after mini-batch  2901: 0.308\n",
      "Loss after mini-batch  3001: 0.309\n",
      "Loss after mini-batch  3101: 0.305\n",
      "Loss after mini-batch  3201: 0.267\n",
      "Loss after mini-batch  3301: 0.286\n",
      "Loss after mini-batch  3401: 0.278\n",
      "Loss after mini-batch  3501: 0.244\n",
      "Loss after mini-batch  3601: 0.240\n",
      "Loss after mini-batch  3701: 0.275\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch   101: 0.249\n",
      "Loss after mini-batch   201: 0.237\n",
      "Loss after mini-batch   301: 0.284\n",
      "Loss after mini-batch   401: 0.239\n",
      "Loss after mini-batch   501: 0.227\n",
      "Loss after mini-batch   601: 0.207\n",
      "Loss after mini-batch   701: 0.276\n",
      "Loss after mini-batch   801: 0.269\n",
      "Loss after mini-batch   901: 0.297\n",
      "Loss after mini-batch  1001: 0.232\n",
      "Loss after mini-batch  1101: 0.245\n",
      "Loss after mini-batch  1201: 0.251\n",
      "Loss after mini-batch  1301: 0.246\n",
      "Loss after mini-batch  1401: 0.228\n",
      "Loss after mini-batch  1501: 0.254\n",
      "Loss after mini-batch  1601: 0.238\n",
      "Loss after mini-batch  1701: 0.252\n",
      "Loss after mini-batch  1801: 0.263\n",
      "Loss after mini-batch  1901: 0.239\n",
      "Loss after mini-batch  2001: 0.250\n",
      "Loss after mini-batch  2101: 0.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch  2201: 0.268\n",
      "Loss after mini-batch  2301: 0.251\n",
      "Loss after mini-batch  2401: 0.311\n",
      "Loss after mini-batch  2501: 0.251\n",
      "Loss after mini-batch  2601: 0.242\n",
      "Loss after mini-batch  2701: 0.249\n",
      "Loss after mini-batch  2801: 0.288\n",
      "Loss after mini-batch  2901: 0.250\n",
      "Loss after mini-batch  3001: 0.215\n",
      "Loss after mini-batch  3101: 0.252\n",
      "Loss after mini-batch  3201: 0.274\n",
      "Loss after mini-batch  3301: 0.225\n",
      "Loss after mini-batch  3401: 0.263\n",
      "Loss after mini-batch  3501: 0.244\n",
      "Loss after mini-batch  3601: 0.267\n",
      "Loss after mini-batch  3701: 0.231\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   101: 0.203\n",
      "Loss after mini-batch   201: 0.208\n",
      "Loss after mini-batch   301: 0.223\n",
      "Loss after mini-batch   401: 0.197\n",
      "Loss after mini-batch   501: 0.222\n",
      "Loss after mini-batch   601: 0.180\n",
      "Loss after mini-batch   701: 0.230\n",
      "Loss after mini-batch   801: 0.214\n",
      "Loss after mini-batch   901: 0.213\n",
      "Loss after mini-batch  1001: 0.248\n",
      "Loss after mini-batch  1101: 0.212\n",
      "Loss after mini-batch  1201: 0.212\n",
      "Loss after mini-batch  1301: 0.219\n",
      "Loss after mini-batch  1401: 0.243\n",
      "Loss after mini-batch  1501: 0.245\n",
      "Loss after mini-batch  1601: 0.226\n",
      "Loss after mini-batch  1701: 0.233\n",
      "Loss after mini-batch  1801: 0.256\n",
      "Loss after mini-batch  1901: 0.223\n",
      "Loss after mini-batch  2001: 0.208\n",
      "Loss after mini-batch  2101: 0.184\n",
      "Loss after mini-batch  2201: 0.240\n",
      "Loss after mini-batch  2301: 0.209\n",
      "Loss after mini-batch  2401: 0.179\n",
      "Loss after mini-batch  2501: 0.196\n",
      "Loss after mini-batch  2601: 0.184\n",
      "Loss after mini-batch  2701: 0.214\n",
      "Loss after mini-batch  2801: 0.228\n",
      "Loss after mini-batch  2901: 0.232\n",
      "Loss after mini-batch  3001: 0.251\n",
      "Loss after mini-batch  3101: 0.254\n",
      "Loss after mini-batch  3201: 0.211\n",
      "Loss after mini-batch  3301: 0.217\n",
      "Loss after mini-batch  3401: 0.247\n",
      "Loss after mini-batch  3501: 0.245\n",
      "Loss after mini-batch  3601: 0.214\n",
      "Loss after mini-batch  3701: 0.243\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   101: 0.185\n",
      "Loss after mini-batch   201: 0.208\n",
      "Loss after mini-batch   301: 0.188\n",
      "Loss after mini-batch   401: 0.211\n",
      "Loss after mini-batch   501: 0.202\n",
      "Loss after mini-batch   601: 0.214\n",
      "Loss after mini-batch   701: 0.211\n",
      "Loss after mini-batch   801: 0.194\n",
      "Loss after mini-batch   901: 0.230\n",
      "Loss after mini-batch  1001: 0.174\n",
      "Loss after mini-batch  1101: 0.212\n",
      "Loss after mini-batch  1201: 0.199\n",
      "Loss after mini-batch  1301: 0.193\n",
      "Loss after mini-batch  1401: 0.228\n",
      "Loss after mini-batch  1501: 0.200\n",
      "Loss after mini-batch  1601: 0.218\n",
      "Loss after mini-batch  1701: 0.218\n",
      "Loss after mini-batch  1801: 0.219\n",
      "Loss after mini-batch  1901: 0.172\n",
      "Loss after mini-batch  2001: 0.233\n",
      "Loss after mini-batch  2101: 0.189\n",
      "Loss after mini-batch  2201: 0.223\n",
      "Loss after mini-batch  2301: 0.228\n",
      "Loss after mini-batch  2401: 0.210\n",
      "Loss after mini-batch  2501: 0.222\n",
      "Loss after mini-batch  2601: 0.221\n",
      "Loss after mini-batch  2701: 0.204\n",
      "Loss after mini-batch  2801: 0.182\n",
      "Loss after mini-batch  2901: 0.206\n",
      "Loss after mini-batch  3001: 0.193\n",
      "Loss after mini-batch  3101: 0.173\n",
      "Loss after mini-batch  3201: 0.202\n",
      "Loss after mini-batch  3301: 0.169\n",
      "Loss after mini-batch  3401: 0.189\n",
      "Loss after mini-batch  3501: 0.216\n",
      "Loss after mini-batch  3601: 0.221\n",
      "Loss after mini-batch  3701: 0.160\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch   101: 0.160\n",
      "Loss after mini-batch   201: 0.196\n",
      "Loss after mini-batch   301: 0.181\n",
      "Loss after mini-batch   401: 0.194\n",
      "Loss after mini-batch   501: 0.190\n",
      "Loss after mini-batch   601: 0.208\n",
      "Loss after mini-batch   701: 0.186\n",
      "Loss after mini-batch   801: 0.191\n",
      "Loss after mini-batch   901: 0.191\n",
      "Loss after mini-batch  1001: 0.233\n",
      "Loss after mini-batch  1101: 0.177\n",
      "Loss after mini-batch  1201: 0.220\n",
      "Loss after mini-batch  1301: 0.263\n",
      "Loss after mini-batch  1401: 0.194\n",
      "Loss after mini-batch  1501: 0.167\n",
      "Loss after mini-batch  1601: 0.181\n",
      "Loss after mini-batch  1701: 0.176\n",
      "Loss after mini-batch  1801: 0.215\n",
      "Loss after mini-batch  1901: 0.164\n",
      "Loss after mini-batch  2001: 0.215\n",
      "Loss after mini-batch  2101: 0.172\n",
      "Loss after mini-batch  2201: 0.175\n",
      "Loss after mini-batch  2301: 0.236\n",
      "Loss after mini-batch  2401: 0.232\n",
      "Loss after mini-batch  2501: 0.162\n",
      "Loss after mini-batch  2601: 0.181\n",
      "Loss after mini-batch  2701: 0.228\n",
      "Loss after mini-batch  2801: 0.177\n",
      "Loss after mini-batch  2901: 0.194\n",
      "Loss after mini-batch  3001: 0.181\n",
      "Loss after mini-batch  3101: 0.213\n",
      "Loss after mini-batch  3201: 0.206\n",
      "Loss after mini-batch  3301: 0.204\n",
      "Loss after mini-batch  3401: 0.188\n",
      "Loss after mini-batch  3501: 0.180\n",
      "Loss after mini-batch  3601: 0.195\n",
      "Loss after mini-batch  3701: 0.186\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with batch size 16: 0.9577\n"
     ]
    }
   ],
   "source": [
    "# Define batch sizes to test\n",
    "batch_sizes = [16, 128]\n",
    "batch_sizes = [16]\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nTraining with batch size: {batch_size}\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model = MlpBatch(\n",
    "        input_size=input_nodes,\n",
    "        hidden_size1=128,\n",
    "        hidden_size2=64,\n",
    "        output_size=output_nodes,\n",
    "        dropout_rate=0.1,\n",
    "        activation=torch.sigmoid,\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    # train(model, criterion, optimizer, train_loader, epochs=5)\n",
    "    train_plt(model, criterion, optimizer, train_loader, epochs=5, batch_size=16)\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Accuracy with batch size {batch_size}: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
